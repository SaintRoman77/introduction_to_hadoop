# introduction_to_hadoop

### Описание:

Разернуть локально docker-контейнер Hadoop, Hive, Parquet and Hue, затем поднять его 
(docker-compose up -d --build), выполнить определенные задачи (описание задач с результатами ниже).

### Описание задач и результаты:

```
1. Подключаемся к контейнеру «datanode-1», создаем внутри папку и переносим в нее скачанные файлы.
```

![](/images/2.jpg)

![](/images/3.jpg)

![](/images/4.jpg)

```
2. Файлы предварительно «схлопываем» в один.
```

![](/images/12.jpg)

![](/images/6.jpg)

```
3. Загружаем полученный файл на hdfs в вашу личную папку.
```

- А также выводим содержимое личной папки:
![](/images/7.jpg)

- Отображение в Hue:
![Отображение в Hue](/images/1.jpg)

```
4. Установите режим доступа, который дает полный доступ для владельца файла, а для сторонних пользователей 
возможность читать и выполнять.
```

![](/images/8.jpg)

```
5. Теперь попробуем вывести на экран информацию о том, сколько места на диске
занимает наш файл. Желательно, чтобы размер файла был удобочитаемым.
```

![](/images/9.jpg)

```
6. Измените фактор репликации на 2.
```

![](/images/10.jpg)

```
7. Напишите команду, которая подсчитывает количество строк.
```

![](/images/11.jpg)
